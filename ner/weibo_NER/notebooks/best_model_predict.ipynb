{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"best_model_predict.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1_ZTDX0W-37v8prxHierIXW-e_TB2SE-x","authorship_tag":"ABX9TyPRaH5tCBK4EE/+2NWtvryo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8UfcL95XQyWs","colab_type":"text"},"source":["使用最优模型预测train+dev数据"]},{"cell_type":"code","metadata":{"id":"pP6veXjnYpeC","colab_type":"code","outputId":"1b28e78d-2c57-42bd-cd07-7ba984ae3d70","executionInfo":{"status":"ok","timestamp":1589988082539,"user_tz":-480,"elapsed":8290,"user":{"displayName":"乔咏田","photoUrl":"","userId":"14672388337264731110"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["# 显卡查看\n","! nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wed May 20 15:21:16 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6aPbMn-HZGp3","colab_type":"code","outputId":"04caa02d-0630-4672-a0ab-1132b7c32c72","executionInfo":{"status":"ok","timestamp":1589988094614,"user_tz":-480,"elapsed":18551,"user":{"displayName":"乔咏田","photoUrl":"","userId":"14672388337264731110"}},"colab":{"base_uri":"https://localhost:8080/","height":827}},"source":["# 依赖安装\n","! pip install fastNLP"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting fastNLP\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/a5/956a2678ee29e7a50b33c06d0390644a184701b585013c94d90106bdcb4c/FastNLP-0.5.5.tar.gz (274kB)\n","\u001b[K     |████████████████████████████████| 276kB 6.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.6/dist-packages (from fastNLP) (1.18.4)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastNLP) (1.5.0+cu101)\n","Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.6/dist-packages (from fastNLP) (4.41.1)\n","Collecting nltk>=3.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 18.4MB/s \n","\u001b[?25hRequirement already satisfied: prettytable>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from fastNLP) (0.7.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastNLP) (2.23.0)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastNLP) (2.2.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from fastNLP) (2019.12.20)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastNLP) (0.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.4.1->fastNLP) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk>=3.4.1->fastNLP) (0.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastNLP) (2020.4.5.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastNLP) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastNLP) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastNLP) (2.9)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastNLP) (0.6.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastNLP) (1.1.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastNLP) (1.0.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastNLP) (7.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastNLP) (46.3.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastNLP) (2.0.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastNLP) (3.0.2)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastNLP) (1.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastNLP) (1.0.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastNLP) (0.4.1)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastNLP) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastNLP) (3.1.0)\n","Building wheels for collected packages: fastNLP, nltk\n","  Building wheel for fastNLP (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastNLP: filename=FastNLP-0.5.5-cp36-none-any.whl size=332757 sha256=00efc36e1d1ace3518f8ad0e0ef9eb114a2a8fc0f0c4b16651a2a31f719c8081\n","  Stored in directory: /root/.cache/pip/wheels/13/b9/4e/7e7b9c2e3deae523b2eec14157ed112ce09bf1dee5483a48ae\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434673 sha256=960bba9a511159cc5497f2497cc2e18f07b072f2f04957c94b4789157f90795f\n","  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n","Successfully built fastNLP nltk\n","Installing collected packages: nltk, fastNLP\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed fastNLP-0.5.5 nltk-3.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m_I6H841ZUI1","colab_type":"text"},"source":["加载数据集"]},{"cell_type":"code","metadata":{"id":"pNXEaqNYZMOm","colab_type":"code","outputId":"fc59abb6-d5ca-4d7d-eda9-ba9b20cf9bae","executionInfo":{"status":"ok","timestamp":1589988105800,"user_tz":-480,"elapsed":26439,"user":{"displayName":"乔咏田","photoUrl":"","userId":"14672388337264731110"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import os\n","import sys\n","import codecs\n","import copy\n","\n","import torch\n","from fastNLP.core import Const\n","from fastNLP.core.predictor import Predictor\n","from fastNLP.io import PeopleDailyNERLoader\n","\n","sys.path.insert(0, '/content/drive/My Drive/my_framework/qyt_clue/')  # 定义搜索路径的优先顺序，序号从0开始，表示最大优先级\n","\n","import myClue  # noqa\n","print('myClue module path :{}'.format(myClue.__file__))  # 输出测试模块文件位置\n","from myClue.core import logger  # noqa\n","from myClue.core.utils import print_data_bundle  # noqa\n","from myClue.tools.serialize import load_serialize_obj  # noqa"],"execution_count":0,"outputs":[{"output_type":"stream","text":["myClue module path :/content/drive/My Drive/my_framework/qyt_clue/myClue/__init__.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WZbeLLNPZfFt","colab_type":"code","outputId":"7b4f978c-c277-4fce-ab2c-9a5482921288","executionInfo":{"status":"ok","timestamp":1589988193291,"user_tz":-480,"elapsed":82957,"user":{"displayName":"乔咏田","photoUrl":"","userId":"14672388337264731110"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# 训练数据预测\n","model_path = '/content/drive/My Drive/my_framework/qyt_clue/data/weibo_NER/model_bert_fine_tuning'\n","model_file = os.path.join(model_path, 'best_BertCRF_f_2020-05-20-06-14-43-235587')\n","train_file = '/content/drive/My Drive/my_framework/qyt_clue/data/weibo_NER/train.conll'\n","predict_output_file = '/content/drive/My Drive/my_framework/qyt_clue/data/weibo_NER/train_bert_predict.conll'\n","char_vocab_pkl_file = os.path.join(model_path, 'vocab_char.pkl')\n","target_vocab_pkl_file = os.path.join(model_path, 'target_char.pkl')\n","# 加载数据\n","data_loader = PeopleDailyNERLoader()\n","data_bundle = data_loader.load({'train': train_file})\n","print_data_bundle(data_bundle)\n","dataset = data_bundle.datasets['train']\n","dataset_original = copy.deepcopy(dataset)\n","# 加载词表\n","char_vocab = load_serialize_obj(char_vocab_pkl_file)\n","logger.info('char_vocab:{}'.format(char_vocab))\n","target_vocab = load_serialize_obj(target_vocab_pkl_file)\n","logger.info('target_vocab:{}'.format(target_vocab))\n","# 加载模型\n","model = torch.load(model_file)\n","if torch.cuda.is_available():\n","    model = model.cuda()\n","    logger.info('use cuda')\n","model.eval()\n","logger.info('模型加载完毕:\\n{}'.format(model))\n","# 数据预处理\n","dataset.rename_field(field_name=Const.RAW_CHAR, new_field_name=Const.INPUT)\n","dataset.add_seq_len(field_name=Const.INPUT)\n","dataset.set_input(Const.INPUT, Const.INPUT_LEN)\n","dataset.set_target(Const.TARGET, Const.INPUT_LEN)\n","char_vocab.index_dataset(dataset, field_name=Const.INPUT)\n","# 预测\n","predictor = Predictor(model)\n","predict_output = predictor.predict(data=dataset, seq_len_field_name=Const.INPUT_LEN)\n","pred_results = predict_output.get(Const.OUTPUT)\n","# 预测结果解码\n","with codecs.open(predict_output_file, mode='w', encoding='utf8') as fw:\n","    for datarow, pred_result in zip(dataset_original, pred_results):\n","        pred_result = [target_vocab.to_word(pred_item) for pred_item in pred_result]\n","        row_chars = datarow[Const.RAW_CHAR]\n","        for char, label in zip(row_chars, pred_result):\n","            fw.write('{}\\t{}\\n'.format(char, label))\n","        fw.write('\\n')\n","    # fw.write('\\n')\n","logger.info('predict_output_file：{}'.format(predict_output_file))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-05-20 15:21:51 I [utils.py:16] dataset name : train\n","2020-05-20 15:21:51 I [utils.py:17] dataset len : 1350\n","2020-05-20 15:21:51 I [utils.py:18] dataset example : \n","2020-05-20 15:21:51 I [utils.py:19] \n","+------------------------------------------+------------------------------------------+\n","| raw_chars                                | target                                   |\n","+------------------------------------------+------------------------------------------+\n","| ['科', '技', '全', '方', '位', '资', ... | ['O', 'O', 'O', 'O', 'O', 'O', 'O', '... |\n","| ['对', '，', '输', '给', '一', '个', ... | ['O', 'O', 'O', 'O', 'O', 'O', 'B-PER... |\n","| ['今', '天', '下', '午', '起', '来', ... | ['O', 'O', 'O', 'O', 'O', 'O', 'O', '... |\n","| ['今', '年', '拜', '年', '不', '短', ... | ['O', 'O', 'O', 'O', 'O', 'O', 'O', '... |\n","| ['浑', '身', '酸', '疼', '，', '两', ... | ['O', 'O', 'O', 'O', 'O', 'O', 'O', '... |\n","+------------------------------------------+------------------------------------------+\n","2020-05-20 15:21:51 I [utils.py:20] dataset 输出各个field的被设置成input和target的情况 : \n","2020-05-20 15:21:51 I [utils.py:21] \n","+-------------+-----------+--------+\n","| field_names | raw_chars | target |\n","+-------------+-----------+--------+\n","|   is_input  |   False   | False  |\n","|  is_target  |   False   | False  |\n","| ignore_type |           |        |\n","|  pad_value  |           |        |\n","+-------------+-----------+--------+\n"],"name":"stderr"},{"output_type":"stream","text":["+-------------+-----------+--------+\n","| field_names | raw_chars | target |\n","+-------------+-----------+--------+\n","|   is_input  |   False   | False  |\n","|  is_target  |   False   | False  |\n","| ignore_type |           |        |\n","|  pad_value  |           |        |\n","+-------------+-----------+--------+\n"],"name":"stdout"},{"output_type":"stream","text":["2020-05-20 15:21:52 I [<ipython-input-4-9c0f8b19b9f4>:16] char_vocab:Vocabulary(['科', '技', '全', '方', '位']...)\n","2020-05-20 15:21:52 I [<ipython-input-4-9c0f8b19b9f4>:18] target_vocab:Vocabulary(['O', 'B-PER.NOM', 'I-PER.NOM', 'B-LOC.NAM', 'I-LOC.NAM']...)\n","2020-05-20 15:22:08 I [<ipython-input-4-9c0f8b19b9f4>:23] use cuda\n","2020-05-20 15:22:08 I [<ipython-input-4-9c0f8b19b9f4>:25] 模型加载完毕:\n","BertCRF(\n","  (embed): BertEmbedding(\n","    (dropout_layer): Dropout(p=0.5, inplace=False)\n","    (model): _BertWordModel(\n","      (encoder): BertModel(\n","        (embeddings): BertEmbeddings(\n","          (word_embeddings): Embedding(3405, 768)\n","          (position_embeddings): Embedding(512, 768)\n","          (token_type_embeddings): Embedding(2, 768)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (encoder): BertEncoder(\n","          (layer): ModuleList(\n","            (0): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (1): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (2): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (3): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (4): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (5): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (6): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (7): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (8): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (9): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (10): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (11): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","          )\n","        )\n","        (pooler): BertPooler(\n","          (dense): Linear(in_features=768, out_features=768, bias=True)\n","          (activation): Tanh()\n","        )\n","      )\n","    )\n","  )\n","  (fc): Linear(in_features=768, out_features=17, bias=True)\n","  (crf): ConditionalRandomField()\n",")\n","2020-05-20 15:23:11 I [<ipython-input-4-9c0f8b19b9f4>:45] predict_output_file：/content/drive/My Drive/my_framework/qyt_clue/data/weibo_NER/train_bert_predict.conll\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5siX3WwZrgtd","colab_type":"code","outputId":"46600c2b-64f3-49ea-8eb7-02aa8e1181ff","executionInfo":{"status":"ok","timestamp":1589988251366,"user_tz":-480,"elapsed":15996,"user":{"displayName":"乔咏田","photoUrl":"","userId":"14672388337264731110"}},"colab":{"base_uri":"https://localhost:8080/","height":593}},"source":["# 训练数据预测\n","train_file = '/content/drive/My Drive/my_framework/qyt_clue/data/weibo_NER/dev.conll'\n","predict_output_file = '/content/drive/My Drive/my_framework/qyt_clue/data/weibo_NER/dev_bert_predict.conll'\n","# 加载数据\n","data_loader = PeopleDailyNERLoader()\n","data_bundle = data_loader.load({'train': train_file})\n","print_data_bundle(data_bundle)\n","dataset = data_bundle.datasets['train']\n","dataset_original = copy.deepcopy(dataset)\n","# 数据预处理\n","dataset.rename_field(field_name=Const.RAW_CHAR, new_field_name=Const.INPUT)\n","dataset.add_seq_len(field_name=Const.INPUT)\n","dataset.set_input(Const.INPUT, Const.INPUT_LEN)\n","dataset.set_target(Const.TARGET, Const.INPUT_LEN)\n","char_vocab.index_dataset(dataset, field_name=Const.INPUT)\n","# 预测\n","predict_output = predictor.predict(data=dataset, seq_len_field_name=Const.INPUT_LEN)\n","pred_results = predict_output.get(Const.OUTPUT)\n","# 预测结果解码\n","with codecs.open(predict_output_file, mode='w', encoding='utf8') as fw:\n","    for datarow, pred_result in zip(dataset_original, pred_results):\n","        pred_result = [target_vocab.to_word(pred_item) for pred_item in pred_result]\n","        row_chars = datarow[Const.RAW_CHAR]\n","        for char, label in zip(row_chars, pred_result):\n","            fw.write('{}\\t{}\\n'.format(char, label))\n","        fw.write('\\n')\n","    # fw.write('\\n')\n","logger.info('predict_output_file：{}'.format(predict_output_file))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-05-20 15:23:55 I [utils.py:16] dataset name : train\n","2020-05-20 15:23:55 I [utils.py:17] dataset len : 270\n","2020-05-20 15:23:55 I [utils.py:18] dataset example : \n","2020-05-20 15:23:55 I [utils.py:19] \n","+------------------------------------------+------------------------------------------+\n","| raw_chars                                | target                                   |\n","+------------------------------------------+------------------------------------------+\n","| ['口', '腔', '溃', '疡', '加', '上', ... | ['O', 'O', 'O', 'O', 'O', 'O', 'O', '... |\n","| ['用', '最', '大', '努', '力', '去', ... | ['O', 'O', 'O', 'O', 'O', 'O', 'O', '... |\n","| ['无', '论', '如', '何', '，', '不', ... | ['O', 'O', 'O', 'O', 'O', 'O', 'O', '... |\n","| ['总', '要', '相', '信', '那', '句', ... | ['O', 'O', 'O', 'O', 'O', 'O', 'O', '... |\n","| ['清', '清', '淡', '然', '朴', '普', ... | ['O', 'O', 'O', 'O', 'O', 'O', 'O', '... |\n","+------------------------------------------+------------------------------------------+\n","2020-05-20 15:23:55 I [utils.py:20] dataset 输出各个field的被设置成input和target的情况 : \n","2020-05-20 15:23:55 I [utils.py:21] \n","+-------------+-----------+--------+\n","| field_names | raw_chars | target |\n","+-------------+-----------+--------+\n","|   is_input  |   False   | False  |\n","|  is_target  |   False   | False  |\n","| ignore_type |           |        |\n","|  pad_value  |           |        |\n","+-------------+-----------+--------+\n"],"name":"stderr"},{"output_type":"stream","text":["+-------------+-----------+--------+\n","| field_names | raw_chars | target |\n","+-------------+-----------+--------+\n","|   is_input  |   False   | False  |\n","|  is_target  |   False   | False  |\n","| ignore_type |           |        |\n","|  pad_value  |           |        |\n","+-------------+-----------+--------+\n"],"name":"stdout"},{"output_type":"stream","text":["2020-05-20 15:24:08 I [<ipython-input-5-1d165135c1ab>:28] predict_output_file：/content/drive/My Drive/my_framework/qyt_clue/data/weibo_NER/dev_bert_predict.conll\n"],"name":"stderr"}]}]}